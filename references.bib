Scopus
EXPORT DATE: 3 August 2025

Ref 1
@ARTICLE{Abujassar2025,
author={Abujassar, R.S.},
title={Intelligent IoT-driven optimization of large-scale healthcare networks: the INRwLF algorithm for adaptive efficiency},
journal={Discover Computing},
year={2025},
}
volume={28},
number={1},
doi={10.1007/s10791-025-09601-6},
art_number={93},

# url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006426540&doi=10.1007%2fs10791-025-09601-6&partnerID=40&md5=1993d4351c92f538614a8ab8dfcf440e},
abstract={Significant research has focused on improving routing performance within centralized Software-Defined Networking (SDN) architectures tailored for Intelligent Internet of Things (I-IoT) environments. With the explosive growth of IoT devices, particularly in expansive and dynamic settings, scalable and energy-conscious routing strategies have become essential. Addressing the limitations of power-constrained nodes, this paper proposes a novel routing algorithm, Interior Neighbors Route with Low Fault (INRwLF), designed for integration within SDN and cloud-enabled infrastructures. Unlike traditional approaches, INRwLF employs an AI-enhanced SDN controller to dynamically construct load-balanced cluster tables and compute fault-tolerant, low-latency paths. Simulation results demonstrate that the protocol reduces energy usage and network delay, while prolonging system lifetime by 50–90%. The proposed approach enhances network efficiency and scalability, particularly in domains such as healthcare, where synchronized data collection and resilient connectivity are critical. © The Author(s) 2025.},
document_type={Article},
source={Scopus},
}

ref 35

@ARTICLE{Zouhri2025,
author={Zouhri, H. and Idri, A.},
title={A novel CTGAN-ENN hybrid approach to enhance the performance and interpretability of machine learning black-box models in intrusion detection and IoT},
journal={Future Generation Computer Systems},
year={2025},
}
volume={173},
doi={10.1016/j.future.2025.107882},
art_number={107882},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005516353&doi=10.1016%2fj.future.2025.107882&partnerID=40&md5=44adf434420ae8467a23ea63465a4c05},
abstract={Class imbalance and high-dimensional data pose significant challenges in intrusion detection systems (IDSs), impacting model performance and interpretability. This paper introduces a novel approach, CTGAN-ENN, combining explainable Conditional Tabular generative adversarial networks (CTGAN) and Edited Nearest Neighbor (ENN) with feature selection (FS) for improving IDS interpretability. The framework operates in three stages: (1) ENN undersamples majority class to reduce overlap and noise, while CTGAN generates realistic synthetic samples for minority classes; (2) two filter-based and two wrapper-based FS techniques are evaluated across three datasets (CICIDS2018, CIC-ToNIoT, NF-UNSW-NB15-v2), with optimal FS-classifier combinations identified using Scott-Knott analysis; and (3) Four interpretability techniques (SHAP, LIME, Global Surrogate (GS), and SHAP summary) are applied for local and global interpretation of four intrusion detection classifiers using two interpretability metrics. The proposed CTGAN-ENN framework is compared with state-of-the-art methods (WGAN, WGAN-GP, SMOTE, ADASYN) using Borda count ranking based on seven model performance metrics, demonstrating superior performance with accuracy rates of 99.99%, 99.64%, and 99.26% on the respective datasets. By integrating SHAP, LIME, and GS, we provide both high performance and a clear understanding of model decisions, making the CTGAN-ENN approach a powerful tool for improving IDSs. Compared to baseline approaches, CTGAN-ENN outperformed all, demonstrating the advantages of combining FS and GAN for simpler, more interpretable models. © 2025 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

ref 25

@ARTICLE{Souza2025,
author={Souza, C.H.M. and Pascoal, T. and Neto, E.P. and Sousa, G.B. and Filho, F.S.L. and Batista, D.M. and Dantas Silva, F.S.},
title={SDN-based solutions for malware analysis and detection: State-of-the-art, open issues and research challenges},
journal={Journal of Information Security and Applications},
year={2025},
}
volume={93},
doi={10.1016/j.jisa.2025.104145},
art_number={104145},

url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009513667&doi=10.1016%2fj.jisa.2025.104145&partnerID=40&md5=c9d7a5fd81a796c7a47078d968f8905d},
abstract={Software-Defined Networking (SDN) has emerged as a key technology for countering evolving malware threats in 5G and Internet-of-Things (IoT) environments. This paper provides a comprehensive survey of SDN-based strategies for malware analysis and detection, consolidating several hundred candidate works and distilling a focused set of studies published up to April 2025. We examine approaches ranging from static code inspection and heuristic traffic monitoring to advanced machine learning and deep learning frameworks, demonstrating that these methods consistently achieve high detection accuracy with low false-positive rates while imposing only modest latency and resource overhead. We illustrate how SDN's centralized control and programmable data plane enable rapid policy updates and real-time mitigation of malicious flows, surpassing traditional network defense mechanisms. Our review clarifies how AI-driven techniques enhance the identification of novel and obfuscated malware, and highlights persistent challenges such as the need for standardized datasets, controller scalability, and privacy-preserving inspection. By synthesizing key insights, open issues, and future research directions, this survey underscores the essential role of SDN in fortifying contemporary cybersecurity architectures. © 2025 Elsevier Ltd},
document_type={Article},
source={Scopus},
}


// Survey Paper (ref 30)


@ARTICLE{Yan2025,
author={Yan, H. and Li, Y.},
title={Generative AI for Intelligent Transportation Systems: Road Transportation Perspective},
journal={ACM Computing Surveys},
year={2025},
}
volume={57},
number={12},
doi={10.1145/3719290},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011248973&doi=10.1145%2f3719290&partnerID=40&md5=b23b02816d8b3baa95fde1d59e5184bc},
abstract={Intelligent transportation systems are vital for modern traffic management and optimization, greatly improving traffic efficiency and safety. With the rapid development of generative artificial intelligence (Generative AI) technologies in areas like image generation and natural language processing, generative AI has also played a crucial role in addressing key issues in intelligent transportation systems (ITS), such as data sparsity, difficulty in observing abnormal scenarios, and in modeling data uncertainty. In this review, we systematically investigate the relevant literature on generative AI techniques in addressing key issues in different types of tasks in ITS tailored specifically for road transportation. First, we introduce the principles of different generative AI techniques. Then, we classify tasks in ITS into four types: traffic perception, traffic prediction, traffic simulation, and traffic decision-making. We systematically illustrate how generative AI techniques addresses key issues in these four different types of tasks. Finally, we summarize the challenges faced in applying generative AI to ITS, and discuss future research directions based on different application scenarios. © 2025 Copyright held by the owner/author(s).},
document_type={Article},
source={Scopus},
}

ref 20

@ARTICLE{Salehiyan2025,
  author    = {Salehiyan, A. and Moghaddam, P.S. and Kaveh, M.},
  title     = {An Optimized Transformer–GAN–AE for Intrusion Detection in Edge and IIoT Systems: Experimental Insights from WUSTL-IIoT-2021, EdgeIIoTset, and TON\_IoT Datasets},
  journal   = {Future Internet},
  year      = {2025},
}

volume={17},
number={7},
doi={10.3390/fi17070279},
art_number={279},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011633595&doi=10.3390%2ffi17070279&partnerID=40&md5=c0471dae659dbb779f060ccf92f4acf9},
abstract={The rapid expansion of Edge and Industrial Internet of Things (IIoT) systems has intensified the risk and complexity of cyberattacks. Detecting advanced intrusions in these heterogeneous and high-dimensional environments remains challenging. As the IIoT becomes integral to critical infrastructure, ensuring security is crucial to prevent disruptions and data breaches. Traditional IDS approaches often fall short against evolving threats, highlighting the need for intelligent and adaptive solutions. While deep learning (DL) offers strong capabilities for pattern recognition, single-model architectures often lack robustness. Thus, hybrid and optimized DL models are increasingly necessary to improve detection performance and address data imbalance and noise. In this study, we propose an optimized hybrid DL framework that combines a transformer, generative adversarial network (GAN), and autoencoder (AE) components, referred to as Transformer–GAN–AE, for robust intrusion detection in Edge and IIoT environments. To enhance the training and convergence of the GAN component, we integrate an improved chimp optimization algorithm (IChOA) for hyperparameter tuning and feature refinement. The proposed method is evaluated using three recent and comprehensive benchmark datasets, WUSTL-IIoT-2021, EdgeIIoTset, and TON_IoT, widely recognized as standard testbeds for IIoT intrusion detection research. Extensive experiments are conducted to assess the model’s performance compared to several state-of-the-art techniques, including standard GAN, convolutional neural network (CNN), deep belief network (DBN), time-series transformer (TST), bidirectional encoder representations from transformers (BERT), and extreme gradient boosting (XGBoost). Evaluation metrics include accuracy, recall, AUC, and run time. Results demonstrate that the proposed Transformer–GAN–AE framework outperforms all baseline methods, achieving a best accuracy of 98.92%, along with superior recall and AUC values. The integration of IChOA enhances GAN stability and accelerates training by optimizing hyperparameters. Together with the transformer for temporal feature extraction and the AE for denoising, the hybrid architecture effectively addresses complex, imbalanced intrusion data. The proposed optimized Transformer–GAN–AE model demonstrates high accuracy and robustness, offering a scalable solution for real-world Edge and IIoT intrusion detection. © 2025 by the authors.},
document_type={Article},
source={Scopus},
}

Ref 4

@ARTICLE{Anantula20255162,
author={Anantula, J. and Likki, V.K.R. and Chaduvula, R.J. and Niloufer, S. and Padmavathi, K. and Panguluri, P. and Kranti, J.U.},
title={CLOUD IOT ENVIRONMENTS SECURITY: DEEP LEARNING WITH GENERATIVE AND EXPLAINABLE MODELS},
journal={Journal of Theoretical and Applied Information Technology},
year={2025},
}
volume={103},
number={12},
pages={5162-5163},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009762987&partnerID=40&md5=f96096e514bc15586080a22457695bab},
abstract={IoT devices have grown exponentially, and businesses are utilizing cloud computing to integrate complex applications with those devices, which poses excellent security concerns regarding confidentiality, integrity, and availability of sensitive data. This paper offers a security framework to mitigate against the threats above utilizing deep learning, Generative Adversarial Networks (GANs), and Explainable AI (XAI). To alleviate the challenges of anomaly detection, especially for rare and novel attacks, the proposed framework uses GANs (Generative Adversarial Networks) to produce synthetic data. XAI methods such as SHAP and LIME have been established to bring more transparency and trust to models, which is incredibly important for security professionals. The framework also integrates federated learning, where models can be trained across decentralized devices while keeping data private. The experimental results demonstrate that our proposed model can achieve achieving94.8% accuracy94.6%precision97.1%recallon NSL-KDD datasets, which are lower than other models Lowest Latency of 45ms per sample. The results validate the model for scalable, interpretable, and privacy-preserving real-time Internet of Things (IoT) security applications. © Little Lion Scientific.},
document_type={Article},
source={Scopus},
}

ref 27

@ARTICLE{W2025,
author={W, A. and Brabin, D.R.D. and Kumar, K.K. and Sunitha, T.},
title={Strengthening security in IoT-based smart cities utilizing cycle-consistent generative adversarial networks for attack detection and secure data transmission},
journal={Peer-to-Peer Networking and Applications},
year={2025},
}
volume={18},
number={2},
doi={10.1007/s12083-024-01838-0},
art_number={79},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218153640&doi=10.1007%2fs12083-024-01838-0&partnerID=40&md5=0ca34965cad1e772ad329e3f36a27105},
abstract={The main purpose of Smart Environments (SE) is to conveniently improve the human's daily life. Internet of Things (IoT) is a developing network for smart objects. Privacy-based security is a significant issue in any real-world smart environments centered on the IoT system. Security susceptibility in the IoT-centered systems provides a risk of security affecting smart environment applications. In this manuscript, Strengthening Security in IoT-Based Smart Cities utilizing Cycle-Consistent Generative Adversarial Networks for Attack Detection and Secure Data Transmission (IoT-SC-CCGAN-ADSDT) is proposed. Here, input information is gathered from NSL-KDD. The NSL-KDD input is pre-processed. Then, the important features of the pre-processed data are selected by using Wild horse optimizer (WHO). After feature selection, the chosen features are provided to cycle-consistent generative adversarial network classifier for classifying the attack and normal data. The selected features are sent to the use after the prediction of outcomes using Advanced Encryption Standard (AES). The AES is optimized using Chameleon Swarm Algorithm for transmitting the data in a safer way. After transmitting the data securely, the normal data outcomes obviously shown in LCD monitor. To show these results, major problems in the smart cities are simply detected. The proposed model is activated using java. The efficiency is examined with performance metrics, like precision, sensitivity, specificity, accuracy, computational time, encryption time, decryption time, security level. The proposed IoT-SC-CCGAN-ADSDT approach provides 96.68%, 7.142%, 94.65%, and 97.58% greater accuracy compared to the existing DL-IOT-SCA, IoT-SC-PCA, IoT-SCA-DL methods respectively. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.},
document_type={Article},
source={Scopus},
}

Ref 7

@ARTICLE{Edozie2025,
author={Edozie, E. and Shuaibu, A.N. and Sadiq, B.O. and John, U.K.},
title={Artificial intelligence advances in anomaly detection for telecom networks},
journal={Artificial Intelligence Review},
year={2025},
}
volume={58},
number={4},
doi={10.1007/s10462-025-11108-x},
art_number={100},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217392036&doi=10.1007%2fs10462-025-11108-x&partnerID=40&md5=e2508bb03e62fef081fcea706e4d4072},
abstract={Telecommunication networks are becoming increasingly dynamic and complex due to the massive amounts of data they process. As a result, detecting abnormal events within these networks is essential for maintaining security and ensuring seamless operation. Traditional methods of anomaly detection, which rely on rule-based systems, are no longer effective in today’s fast-evolving telecom landscape. Thus, making AI useful in addressing these shortcomings. This review critically examines the role of Artificial Intelligence (AI), particularly deep learning, in modern anomaly detection systems for telecom networks. It explores the evolution from early strategies to current AI-driven approaches, discussing the challenges, the implementation of machine learning algorithms, and practical case studies. Additionally, emerging AI technologies such as Generative Adversarial Networks (GANs) and Reinforcement Learning (RL) are highlighted for their potential to enhance anomaly detection. This review provides AI’s transformative impact on telecom anomaly detection, addressing challenges while leveraging 5G/6G, edge computing, and the Internet of Things (IoT). It recommends hybrid models, advanced data preprocessing, and self-adaptive systems to enhance robustness and reliability, enabling telecom operators to proactively manage anomalies and optimize performance in a data driven environment. © The Author(s) 2025.},
document_type={Article},
source={Scopus},
}

ref 17

@ARTICLE{Prasanth2025,
author={Prasanth, L.L. and Uma, E.},
title={Revolutionizing neurostimulator care: enhancing remote health monitoring through SDN-cloud networks},
journal={Telecommunication Systems},
year={2025},
}
volume={88},
number={1},
doi={10.1007/s11235-024-01255-x},
art_number={12},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214129852&doi=10.1007%2fs11235-024-01255-x&partnerID=40&md5=ec171de48d564325ea3c29e752aef529},
abstract={The Internet of Things (IoT) and artificial intelligence (AI) are rapidly advancing technologies with significant implications for healthcare. This study aims to develop and evaluate a remote healthcare monitoring (RHM) model that integrates an auricular therapy device with Software Defined Networking (SDN) and cloud networks to enhance neurostimulator care in smart cities. The auricular therapy device collects brain signal data non-invasively through the outer ear and communicates via Bluetooth between patient and doctor smartphones. The collected data is processed to eliminate noise and normalized before classification using an adaptive fuzzy based Bayesian metasalp neural network (AFBBMNN) combined with levy flight secure offloading analysis within an SDN framework. The processed data is then transmitted to doctors via a cloud-SDN module, consisting of a communication phase, cloud server, and cloud database. Results demonstrate significant improvements in remote health monitoring, enabling early detection of neurological conditions and enhancing healthcare provision within a smart city framework. The proposed method shows promise as an efficient tool for early neurological disease detection and treatment. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.},
document_type={Article},
source={Scopus},
}

ref 23

@ARTICLE{daSilvaRuffo2025,
author={da Silva Ruffo, V.G. and Lent, D.M.B. and Carvalho, L.F. and Lloret, J. and Proença, M.L., Jr.},
title={Generative adversarial networks to detect intrusion and anomaly in IP flow-based networks},
journal={Future Generation Computer Systems},
year={2025},
}
volume={163},
doi={10.1016/j.future.2024.107531},
art_number={107531},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204371055&doi=10.1016%2fj.future.2024.107531&partnerID=40&md5=a976ce2486cb78c5a44a8c03765abfaa},
abstract={Computer networks facilitate regular human tasks, providing services like data streaming, online shopping, and digital communications. These applications require more and more network capacity and dynamicity to accomplish their goals. The networks may be targeted by attacks and intrusions that compromise the applications that rely on them and lead to potential losses. We propose a semi-supervised systematic methodology for developing a detection system for traffic volume anomalies in IP flow-based networks. The system is implemented with a vanilla Generative Adversarial Network (GAN). The mitigation module is triggered whenever an anomaly is detected, automatically blocking the suspect IPs and restoring the correct network functioning. We implemented three versions of the proposed solution by incorporating Long Short-Term Memory (LSTM), 1D-Convolutional Neural Network (1D-CNN), and Temporal Convolutional Network (TCN) into the GAN internal structure. The experiments are conducted on three public benchmark datasets: Orion, CIC-DDoS2019, and CIC-IDS2017. The results show that the three considered deep learning models have distinct impacts on the GAN model and, consequently, on the overall system performance. The 1D-CNN-based GAN implementation is the best since it reasonably solves the mode collapse problem, has the most efficient computational complexity, and achieves competitive Matthews Correlation Coefficient scores for the anomaly detection task. Also, the mitigation module can drop most anomalous flows, blocking only a slight portion of legitimate traffic. For comparison with state-of-the-art models, we implemented 1D-CNN, LSTM, and TCN separately from the GAN. The generative networks show improved overall results in the considered performance metrics compared to the other models. © 2024},
document_type={Article},
source={Scopus},
}

ref 21

@ARTICLE{Sefati2025,
author={Sefati, S.S. and Arasteh, B. and Craciunescu, R. and Comsa, C.-R.},
title={Intelligent Congestion Control in Wireless Sensor Networks (WSN) Based on Generative Adversarial Networks (GANs) and Optimization Algorithms},
journal={Mathematics},
year={2025},
}
volume={13},
number={4},
doi={10.3390/math13040597},
art_number={597},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219570311&doi=10.3390%2fmath13040597&partnerID=40&md5=195fda6f7b5f6c71a7ed9698966e2e90},
abstract={Internet of Things (IoT) technology has facilitated the deployment of autonomous sensors in remote and challenging environments, enabling substantial advancements in environmental monitoring and data collection. IoT sensors continuously gather data, transmitting it to a central Base Station (BS) via designated Cluster Heads (CHs). However, data flow encounters frequent congestion at CH nodes, negatively impacting network performance and Quality of Service (QoS). This paper introduces a novel congestion control strategy tailored for Wireless Sensor Networks (WSNs) to balance energy efficiency and data reliability. The proposed approach follows an eight-step process, integrating Generative Adversarial Networks (GANs) for enhanced clustering and Ant Colony Optimization (ACO) for optimal CH selection and routing. GANs simulate realistic node clustering, achieving better load distribution and energy conservation across the network. ACO then selects CHs based on energy levels, distance, and network centrality, using pheromone-based routing to adaptively manage data flows. A congestion factor (CF) threshold is also incorporated to dynamically reroute traffic when congestion risks arise, preserving QoS. Simulation results show that this approach significantly improves QoS metrics, including latency, throughput, and reliability. Comparative evaluations reveal that our method outperforms existing frameworks, such as Fuzzy Structure and Genetic-Fuzzy (FSFG), Deep Reinforcement Learning Cache-Aware Congestion Control (DRL-CaCC), and Adaptive Cuckoo Search Rate Optimization (ACSRO). © 2025 by the authors.},
document_type={Article},
source={Scopus},
}

ref 11

@ARTICLE{Li2025,
author={Li, M. and Luo, L. and Xiao, K. and Wang, G. and Wang, Y.},
title={Adaptive Semi-Supervised Algorithm for Intrusion Detection and Unknown Attack Identification},
journal={Applied Sciences (Switzerland)},
year={2025},
}
volume={15},
number={4},
doi={10.3390/app15041709},
art_number={1709},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218627731&doi=10.3390%2fapp15041709&partnerID=40&md5=8e145c5d503c5ec7c83c6875e7ccf317},
abstract={Intrusion detection systems face significant challenges, including the inability to detect unknown threats and imbalances between normal and anomalous traffic. To address these limitations, we propose a semi-supervised intrusion detection algorithm based on GAN with a Transformer backbone for network security in IoT devices. To address the issue of imbalanced normal and anomalous traffic due to the diversity of network behavior and the difficulty that supervised algorithms experience in detecting unknown intrusions, we use only normal traffic as training data. By integrating the self-attention mechanism of Transformers, we leverage their ability to capture long-range dependencies in sequential data, enhancing the core capability of the GAN. The experimental results show that our algorithm achieves an F1-score of 95.2% and a false omission rate (FOR) of 10.7% on the CIC-IDS2017 dataset. On the Kitsune dataset, it attains an F1-score of 83.2% and a FOR of 15.8%. In real-world applications, when the algorithm was deployed on actual vehicle devices, it maintained strong performance with a FOR of 13%, further validating the practical applicability and value of the algorithm. © 2025 by the authors.},
document_type={Article},
source={Scopus},
}

ref 13

@ARTICLE{Lv202523536,
author={Lv, J. and Babbar, H. and Rani, S.},
title={AI-Driven Resource Management for Energy-Efficient Aerial Computing in Large-Scale Healthcare SDN–IoT Systems},
journal={IEEE Internet of Things Journal},
year={2025},
}
volume={12},
number={13},
pages={23536-23549},
doi={10.1109/JIOT.2025.3556943},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001968518&doi=10.1109%2fJIOT.2025.3556943&partnerID=40&md5=ae067f4b0607ebc46d829f1f40c28211},
abstract={The integration of software-defined networking (SDN) and the Internet of Things (IoT) presents significant challenges in large-scale healthcare systems, particularly in terms of optimizing resource allocation, managing energy consumption (EC), and ensuring real-time data processing. This research introduces an AI-driven resource management framework designed to address these challenges. Using autonomous aerial vehicles (AAVs) for aerial computing, the framework optimizes energy usage, reduces network latency, and enhances anomaly detection through machine learning models. Key contributions include dynamic allocation of bandwidth and processing resources, adaptive power management, and real-time traffic prediction, ensuring high Quality of Service (QoS) even in resource-constrained environments. The simulation results demonstrate a 10%–15% reduction in EC, 15% decrease in latency, and improved real-time data processing, making the system ideal for critical healthcare applications such as telemedicine and remote monitoring. The framework offers a scalable solution to efficiently manage the growing number of IoT devices and AAVs, while also maintaining a low-latency secure service delivery. © 2014 IEEE.},
document_type={Article},
source={Scopus},
}

ref 31

@ARTICLE{Zabeehullah2025,
author={Zabeehullah and Haq, Q.M.U. and Arif, F. and Anwar, M.S. and Alhalabi, W. and Khan, N.A.},
title={A Secure AI Framework for Intelligent Traffic Prediction and Routing in SDN Based Consumer Internet of Things},
journal={IEEE Transactions on Consumer Electronics},
year={2025},
}
doi={10.1109/TCE.2025.3552609},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001178557&doi=10.1109%2fTCE.2025.3552609&partnerID=40&md5=68369c647175e837bebd1371dec678a2},
abstract={With the rapid increase of Consumer Internet of Things (CIoT) and advancements in communication technologies, both are generating a huge amount of imbalance data. Traditional network architectures struggle to handle the complex and heterogeneous nature of CIoT devices, as well as the imbalance and unpredictability of traffic flows. Software Defined Networking (SDN) is a novel networking paradigm. By decoupling the data plane from the control plane, it efficiently manages the complexity and heterogeneity of CIoT devices. However, challenges such as imbalance data security, future traffic load prediction, and optimized routing still persist in CIoT environment. Advancements in Deep Learning (DL) algorithms, along with their extensive application in CIoT domain, have enabled resolving SDN-CIoT security and performance issues. To address the above mentioned challenges, in this article, we propose an AI-based framework which comprises two modules: 1) DL-based security and traffic load prediction module and 2) DRL-based routing optimization module. In addition, the proposed framework employs the CNN based intelligent load balancing strategy among SDN controllers to reduce the computational burden on the main controller. The performance of the proposed model is evaluated through simulation and results demonstrate that the proposed framework achieved excellent performance compared to the state-of-the art methods. © 2025 IEEE.},
document_type={Article},
source={Scopus},
}

// Survey paper ( ref 18 in citations )

@ARTICLE{Rong2025,
author={Rong, R. and Ma, S. and Ren, N. and Lin, Q. and Jia, N.},
title={Generative artificial intelligence in intelligent transportation systems: A systematic review of applications},
journal={Frontiers of Engineering Management},
year={2025},
}
doi={10.1007/s42524-025-4241-9},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003765722&doi=10.1007%2fs42524-025-4241-9&partnerID=40&md5=abd7a914fe5de69c314b81064e822bcc},
abstract={Rapid urbanization is reshaping mobility demands, calling for advanced intelligence and management capabilities in urban transport systems. Generative Artificial Intelligence (AI) presents new opportunities to enhance the efficiency and responsiveness of Intelligent Transportation Systems (ITS). This paper reviews the existing literature in transportation and AI to investigate the core technologies of Artificial Intelligence Generated Content (AIGC)–including dialog and reasoning, prediction and decision making, and multimodal generation. Applications are summarized across the four primary ITS subsystems (road subsystem, vehicle subsystem, traveler subsystem and management subsystem). This paper finds that AIGC has become an important way to promote the progress and development of ITS by exploring the research progress of cutting-edge technologies such as data generation, assisted driving decision-making, and intelligent traffic prediction. Meanwhile, this paper explores the potential challenges that AIGC brings to human society from the perspectives of safety risks of fake content, human-machine relationships, social cognition and emotional trust, and related ethical issues, providing insights for the development of safer and more sustainable ITS in the future. © The Author(s) 2025.},
document_type={Review},
source={Scopus},
}

ref 34

@ARTICLE{Zheng20251011,
author={Zheng, Z.-X. and Chen, F.},
title={An IoT Intrusion Detection Method Combining GAN and Transformer Neural Networks},
journal={Journal of Network Intelligence},
year={2025},
}
volume={10},
number={2},
pages={1011-1026},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007470324&partnerID=40&md5=c0a8d8e238ad053e8ee32a78cdffc168},
abstract={Tackling the security issues inherent in the Internet of Things (IoT) neces-sitates the critical deployment of Intrusion Detection Systems (IDS). Presently, machine learning and deep learning techniques are widely employed for IoT intrusion detection. However, the imbalance in relevant datasets leads models to predominantly learn the characteristics of majority class data, neglecting those of minority class data, thereby significantly impairing detection accuracy. Additionally, in deep learning-based IDS, at-tackers can deceive the system by adding perturbations, causing it to misidentify malicious traffic as benign. To counter this, adversarial sample generation methods based on Generative Adversarial Networks (GANs) are employed. GANs use neural ordinary differential equations as generators and Wasserstein distance as the loss function, allowing the generator to better learn the distribution of genuine samples and improve the quality of adversarial samples. This approach allows the model to better learn the characteristics of underrepresented data, improving overall detection accuracy. A model combining Transformers with Bidirectional Gated Recurrent Units (Bi-GRU) is proposed for IoT intrusion detection. The Transformer encoder captures global relationships and performs initial feature extraction on input data, while the Bi-GRU network extracts long-distance dependency features, preserving the sequential characteristics of the data. A Multi-Layer Perceptron (MLP) further extracts deep features, and a Softmax classifier ultimately provides the classification results. The efficacy of the proposed approach was substan-tiated through testing on the publicly available ToN IoT dataset for intrusion detection within IoT environments. Experimental results show that the GAN-Transformer framework achieved average precision, recall, and F1 score of 97.62%, 97.66%, and 97.64%, respectively. When compared with other cutting-edge techniques, the proposed approach exhibited markedly enhanced detection performance. © 2025, Taiwan Ubiquitous Information CO LTD. All rights reserved.},
document_type={Article},
source={Scopus},
}

ref 14

@ARTICLE{Naseer2025,
author={Naseer, F. and Addas, A. and Tahir, M. and Khan, M.N. and Sattar, N.},
title={Integrating generative adversarial networks with IoT for adaptive AI-powered personalized elderly care in smart homes},
journal={Frontiers in Artificial Intelligence},
year={2025},
}
volume={8},
doi={10.3389/frai.2025.1520592},
art_number={1520592},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219207505&doi=10.3389%2ffrai.2025.1520592&partnerID=40&md5=388ca7bafd9be45a58193d8679ea8d53},
abstract={The need for effective and personalized in-home solutions will continue to rise with the world population of elderly individuals expected to surpass 1.6 billion by the year 2050. The study presents a system that merges Generative Adversarial Network (GAN) with IoT-enabled adaptive artificial intelligence (AI) framework for transforming personalized elderly care within the smart home environment. The reason for the application of GANs is to generate synthetic health data, which in turn addresses the scarcity of data, especially of some rare but critical conditions, and helps enhance the predictive accuracy of the system. Continuous data collection from IoT sensors, including wearable sensors (e.g., heart rate monitors, pulse oximeters) and environmental sensors (e.g., temperature, humidity, and gas detectors), enables the system to track vital indications of health, activities, and environment for early warnings and personalized suggestions through real-time analysis. The AI adapts to the unique pattern of healthy and behavioral habits in every individual’s lifestyle, hence offering personalized prompts, reminders, and sends off emergency alert notifications to the caregiver or health provider, when required. We were showing significant improvements like 30% faster detection of risk conditions in a large-scale real-world test setup, and 25% faster response times compared with other solutions. GANs applied to the synthesis of data enable more robust and accurate predictive models, ensuring privacy with the generation of realistic yet anonymized health profiles. The system merges state-of-the-art AI with GAN technology in advancing elderly care in a proactive, dignified, secure environment that allows improved quality of life and greater independence for the aging individual. The work hence provides a novel framework for the utilization of GAN in personalized healthcare and points out that this will help reshape elderly care in IoT-enabled “smart” homes. Copyright © 2025 Naseer, Addas, Tahir, Khan and Sattar.},
document_type={Article},
source={Scopus},
}

Ref 2
@ARTICLE{Almadhor2025,
author={Almadhor, A. and Sampedro, G.A. and Zaidi, M.M. and Juanatas, R.A. and Hejaili, A.A.},
title={Generative AI-Driven Context-Aware BDI-Based Smart Routing Protocol for Intelligent Transportation Systems},
journal={IEEE Transactions on Intelligent Transportation Systems},
year={2025},
}
doi={10.1109/TITS.2025.3570237},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010906936&doi=10.1109%2fTITS.2025.3570237&partnerID=40&md5=bf010a592d26e67bbc281b2551585350},
abstract={This research introduces a newly proposed Belief-Desire-Intention (BDI) agent-based Smart Routing Protocol for Intelligent Transportation Systems (ITS) that leverages context-aware decision-making inspired by Generative Artificial Intelligence (GAI) reasoning models. The protocol enhances routing decisions by considering real-time traffic conditions, weather, road blockages, peak-hour dynamics, and AI-generated predictions of future congestion. By incorporating BDI reasoning, the system dynamically adjusts routes based on both current and forecasted conditions, thereby improving the overall performance of vehicular networks. Our proposed system aims to optimise key performance indicators such as Packet Delivery Ratio (PDR), End-to-End Delay, Throughput, Control Overhead, Traffic Flow, Routing Decision Accuracy, and Energy Consumption. Simulation results demonstrate that the BDI-based system outperforms traditional routing protocols like Ad hoc On-Demand Distance Vector (AODV) and Dynamic Source Routing (DSR), showing significant improvements in PDR, Throughput, and Energy Efficiency. For example, the BDI-based system achieved a PDR of 98%, compared to 85% for AODV and 80% for DSR. Additionally, the BDI protocol reduced end-to-end delay by 25% and energy consumption by 30% compared to the baseline protocols. These findings underscore the BDI-based system’s capability for real-time, adaptive routing in ITS, enabling optimal network performance and resource efficiency through context-aware and predictive routing decisions. © 2000-2011 IEEE.},
document_type={Article},
source={Scopus},
}

Ref 8

@ARTICLE{Fu2024,
author={Fu, T. and Hao, S. and Chen, Q. and Yan, Z. and Liu, H. and Rezaeipanah, A.},
title={An energy-aware secure routing scheme in internet of things networks via two-way trust evaluation},
journal={Pervasive and Mobile Computing},
year={2024},
}
volume={105},
doi={10.1016/j.pmcj.2024.101995},
art_number={101995},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207101372&doi=10.1016%2fj.pmcj.2024.101995&partnerID=40&md5=ca43f4d09565c6d5bc94bdcf8f457a0e},
abstract={The rapid advancement of technology has led to the proliferation of devices connected to the Internet of Things (IoT) networks, bringing forth challenges in both energy management and secure data communication. In addition to energy constraints, IoT networks face threats from malicious nodes, which jeopardize the security of communications. To address these challenges, we propose an Energy-aware secure Routing scheme via Two-Way Trust evaluation (ERTWT) for IoT networks. This scheme enhances network protection against various attacks by calculating trust values based on energy trust, direct trust, and indirect trust. The scheme aims to enhance the efficiency of data transmission by dynamically selecting routes based on both energy availability and trustworthiness metrics of fog nodes. Since trust management can guarantee privacy and security, ERTWT allows the service requester and the service provider to check each other's safety and reliability at the same time. In addition, we implement Generative Flow Networks (GFlowNets) to predict the energy levels available in nodes in order to use them optimally. The proposed scheme has been compared with several advanced energy-aware and trust-based routing protocols. Evaluation results show that ERTWT more effectively detects malicious nodes while achieving better energy efficiency and data transmission rates. © 2024 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

ref 22

@article{seng2022artificial,
  title={Artificial intelligence Internet of Things: A new paradigm of distributed sensor networks},
  author={Seng, Kah Phooi and Ang, Li Minn and Ngharamike, Ericmoore},
  journal={International Journal of Distributed Sensor Networks},
  volume={18},
  number={3},
  pages={15501477211062835},
  year={2022},
  publisher={SAGE Publications Sage UK: London, England},
  abstract = {The advances and convergence in sensor, information processing, and communication technologies have shaped the Internet of Things of today. The rapid increase of data and service requirements brings new challenges for Internet ofThing. Emerging technologies and intelligent techniques can play a compelling role in prompting the development of intelligent architectures and services in Internet of Things to form the artificial intelligence Internet of Things. In this article,we give an introduction and review recent developments of artificial intelligence Internet of Things, the various artificial intelligence Internet of Things computational frameworks and highlight the challenges and opportunities for effective deployment of artificial intelligence Internet of Things technology to address complex problems for various applications. This article surveys the recent developments and discusses the convergence of artificial intelligence and Internet of Things from four aspects: (1) architectures, techniques, and hardware platforms for artificial intelligence Internet of Things; (2) sensors, devices, and energy approaches for artificial intelligence Internet of Things; (3) communication andnetworking for artificial intelligence Internet of Things; and (4) applications for artificial intelligence Internet of Things. The article also discusses the combination of smart sensors, edge computing, and software-defined networks as enabling technologies for the artificial intelligence Internet of Things.}
}


ref 26

@ARTICLE{Swathi202410653,
author={Swathi, B. and Kolisetty, S.S. and Sivanarayana, G.V. and Battula, S.R.},
title={Efficientnetv2-RegNet: an effective deep learning framework for secure SDN based IOT network},
journal={Cluster Computing},
year={2024},
}
volume={27},
number={8},
pages={10653-10670},
doi={10.1007/s10586-024-04498-0},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192542499&doi=10.1007%2fs10586-024-04498-0&partnerID=40&md5=1552d43d80d2e5467c3354fafd7d07f2},
abstract={Traditional network administration required manual programming of routing policies and related parameters on specific routers and switches, which was expensive. Therefore, software-defined networking (SDN) technology has been introduced, which has boosted flexibility and decreased hardware development costs by centralizing network management. Since intrusion detection is vital in the SDN environment, this centralized architecture makes information security vulnerable to network threats. To evaluate and recognize these attacks, many researchers have recently adopted cutting-edge approaches like machine learning. However, most of these methods are not very accurate and scalable. To address this issue, this paper proposes an EfficientNetV2-RegNet-based effective deep learning technique. It effectively extracted the network features and classified the intrusions in SDN-based IoT (Internet of Things). Afterwards, an effective mitigation process was performed by a remote SDN controller to mitigate the assaults and reconfigure the network resources for trusted network hosts. Furthermore, the Conditional Generative Adversarial Network (CGAN) based data augmentation approach efficiently tackles the data imbalance issue. The most recent realistic datasets, named InSDN and IoT-23, were utilized to train and assess the presented framework to validate its efficiency. The results of the experiments demonstrated that the suggested system surpassed competitors in identifying various attack types and achieved 99.53 and 99.56% accuracy for IoT-23 and InSDN datasets, correspondingly. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
document_type={Article},
source={Scopus},
}

Ref 3

@ARTICLE{Alnaser2024,
author={Alnaser, A.M.A. and Saloum, S.S. and Sharadqh, A.A.M. and Hatamleh, H.},
title={Optimizing Multi-Tier Scheduling and Secure Routing in Edge-Assisted Software-Defined Wireless Sensor Network Environment Using Moving Target Defense and AI Techniques},
journal={Future Internet},
year={2024},
}
volume={16},
number={11},
doi={10.3390/fi16110386},
art_number={386},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210264087&doi=10.3390%2ffi16110386&partnerID=40&md5=d14cd0a48f8095a4968ad6f70e254801},
abstract={Software Defined Wireless Sensor Networks (SDWSN) enable flexibility in Wireless Sensor Network (WSN) environments by defining the controllable functions to WSN nodes by the Software Defined Network (SDN) controller. Due to the rapid evolution of SDWSNs, adverse effects also have occurred in terms of interference, energy consumption, and security issues. Several state-of-the-art works lend their utmost best to the SDWSN environment. However, the complete picture (i.e., relatability and security in SDWSN) poses severe challenges. The state-of-the-art issues is addressed in this research by proposing interference-aware Multi-Tier Scheduling for the SDWSN environment (MTS-SDWSN). First, we perform network construction in which the proposed network is constructed in a 2D hexagonal grid structure to resolve the connectivity issue. Upon constructing the network, the SDWSN nodes are clustered and managed to reduce the energy consumption using the Divide Well To Merge Better (DWTMB) algorithm in which the optimal Cluster Leader (CL) is selected based on adequate constraint. The data from the clustered nodes are sent to the Local Base Station (LBS) via CL in which they are scheduled in multi-tier format to diminish the complexity and interference issues. The first tier involved in scheduling among Cluster Members (CMs) and CL using adequate metrics, whereas the successive tiers (i.e., second and third) involved in scheduling among CLs to LBSs and LBSs to Sink Node (SN) are done using the Non-Cooperative Fuzzy Theory (NCFT) method. Last, the scheduled nodes are routed to appropriate destinations using Secure and Optimal Routing Protocol (SORP). The proposed SORP includes the Alibaba and Forty Thieves (AFT) and Multi Criteria Decision Making (MCDM) algorithms for selecting and ranking the optimal routes. Further, the security of the routes is enabled by adopting trust and Moving Target Defense (MTD) mechanisms. The MTD includes route switching among the SDWSN devices and active switch handling using Cycle Generative Adversarial Networks (CGAN) among the switches. The proposed work is implemented using a NS-3.26 simulation tool, and performance of the proposed model and existing works shows that the proposed work outperforms the existing works. © 2024 by the authors.},
document_type={Article},
source={Scopus},
}

Review/Survey Paper (Ref 19 in citations) 

@ARTICLE{Saadouni20248655,
author={Saadouni, R. and Gherbi, C. and Aliouat, Z. and Harbi, Y. and Khacha, A.},
title={Intrusion detection systems for IoT based on bio-inspired and machine learning techniques: a systematic review of the literature},
journal={Cluster Computing},
year={2024},
}
volume={27},
number={7},
pages={8655-8681},
doi={10.1007/s10586-024-04388-5},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190415849&doi=10.1007%2fs10586-024-04388-5&partnerID=40&md5=3e180f442d551edb852e987ce97a8770},
abstract={Recent technological advancements have significantly expanded both networks and data, thereby introducing new forms of attacks that pose considerable challenges to intrusion detection and network security. With intruders deploying increasingly diverse attack vectors, the need for robust Intrusion Detection Systems (IDSes) has become paramount. IDS serves as a crucial tool for monitoring network traffic to uphold the integrity, confidentiality, and availability of systems. Despite the integration of Machine Learning (ML) and Deep Learning (DL) algorithms into IDS frameworks, achieving higher accuracy levels while minimizing false alarms remains a challenging task, especially when handling large datasets. In response to this challenge, researchers have turned to bio-inspired algorithms as potential solutions to enhance IDS models. This paper undertakes a comprehensive literature review focusing on augmenting the security of Internet of Things (IoT) networks by integrating bio-inspired methodologies with ML and DL techniques. Among 145 published articles, 25 relevant studies were selected to address the defined research objectives. The findings underscore the efficacy of combining bio-inspired techniques with ML and DL approaches in enhancing IDS performance, highlighting their potential to bolster IoT network security. Furthermore, the review incorporates a comparative analysis of the selected articles, considering various factors, and outlines ongoing challenges and future directions in integrating bio-inspired techniques with ML and DL algorithms. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
document_type={Article},
source={Scopus},
}

ref 32

@ARTICLE{Zacaron2024,
author={Zacaron, A.M. and Lent, D.M.B. and da Silva Ruffo, V.G. and Carvalho, L.F. and Proença, M.L., Jr.},
title={Generative Adversarial Network Models for Anomaly Detection in Software-Defined Networks},
journal={Journal of Network and Systems Management},
year={2024},
}
volume={32},
number={4},
doi={10.1007/s10922-024-09867-z},
art_number={93},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203800389&doi=10.1007%2fs10922-024-09867-z&partnerID=40&md5=68fbf02a89aeb9e15a58bcf6397fbe70},
abstract={Software-defined Networking (SDN) is a modern network management paradigm that decouples the data and control planes. The centralized control plane offers comprehensive control and orchestration over the network infrastructure. Although SDN provides better control over traffic flow, ensuring network security and service availability remains challenging. This paper presents an anomaly-based intrusion detection system (IDS) for monitoring and securing SDN networks. The system utilizes deep learning models to identify anomalous traffic behavior. When an anomaly is detected, a mitigation module blocks suspicious communications and restores the network to its normal state. Three versions of the proposed solution were implemented and compared: the traditional Generative Adversarial Network (GAN), Deep Convolutional GAN (DCGAN), and Wasserstein GAN with Gradient Penalty (WGAN-GP). These models were incorporated into the system’s detection structure and tested on two benchmark datasets. The first is emulated, and the second is the well-known CICDDoS2019 dataset. The results indicate that the IDS adequately identified potential threats, regardless of the deep learning algorithm. Although the traditional GAN is a simpler model, it could still efficiently detect when the network was under attack and was considerably faster than the other models. Additionally, the employed mitigation strategy successfully dropped over 89% of anomalous flows in the emulated dataset and over 99% in the public dataset, preventing the effects of the threats from being accentuated and jeopardizing the proper functioning of the SDN network. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
document_type={Article},
source={Scopus},
}

ref 29

@ARTICLE{Wang2024427,
author={Wang, J. and Zhang, Y. and Xing, X. and Zhan, Y. and Chan, W.K.V. and Tiwari, S.},
title={A data-driven system for cooperative-bus route planning based on generative adversarial network and metric learning},
journal={Annals of Operations Research},
year={2024},
}
volume={339},
number={1-2},
pages={427-453},
doi={10.1007/s10479-022-04842-w},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139241841&doi=10.1007%2fs10479-022-04842-w&partnerID=40&md5=7f5086580dd6071e168a0ef2e00f8874},
abstract={Faced with dynamic and increasingly diversified public transport requirements, bus operators are urged to propose operational innovations to sustain their competitiveness. In particular, ordinary bus operations are heavily constrained by well-established route options, and it is challenging to accommodate dynamic passenger flows effectively and with a good level of resource utilization performance. Inspired by the philosophy of sharing economy, many of the available transport resources on the road, such as minibuses and private vehicles, can offer opportunities for improvement if they can be effectively incorporated and exploited. In this regard, this paper proposes a metric learning-based prediction algorithm which can effectively capture the demand pattern and designs a route planning optimizer to help bus operators effectively deploy fixed routing and cooperative buses with traffic dynamics. Through extensive numerical studies, the performance of our proposed metric learning-based Generative Adversarial Network (GAN) prediction model outperforms existing ways. The effectiveness and robustness of the prediction-supported routing planner are well demonstrated for a real-time case. Further, managerial insights with regard to travel time, bus fleet size, and customer service levels are revealed by various sensitivity analysis. © The Author(s) 2022.},
document_type={Article},
source={Scopus},
}

// Survey paper ( ref 15 in citations )


@ARTICLE{OspinaCifuentes2024,
author={Ospina Cifuentes, B.J. and Suárez, Á. and García Pineda, V. and Alvarado Jaimes, R. and Montoya Benitez, A.O. and Grajales Bustamante, J.D.},
title={Analysis of the Use of Artificial Intelligence in Software-Defined Intelligent Networks: A Survey},
journal={Technologies},
year={2024},
}
volume={12},
number={7},
doi={10.3390/technologies12070099},
art_number={99},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199878536&doi=10.3390%2ftechnologies12070099&partnerID=40&md5=29f156d11a70f701c0f11fbc3f2ed6cd},
abstract={The distributed structure of traditional networks often fails to promptly and accurately provide the computational power required for artificial intelligence (AI), hindering its practical application and implementation. Consequently, this research aims to analyze the use of AI in software-defined networks (SDNs). To achieve this goal, a systematic literature review (SLR) is conducted based on the PRISMA 2020 statement. Through this review, it is found that, bottom-up, from the perspective of the data plane, control plane, and application plane of SDNs, the integration of various network planes with AI is feasible, giving rise to Intelligent Software Defined Networking (ISDN). As a primary conclusion, it was found that the application of AI-related algorithms in SDNs is extensive and faces numerous challenges. Nonetheless, these challenges are propelling the development of SDNs in a more promising direction through the adoption of novel methods and tools such as route optimization, software-defined routing, intelligent methods for network security, and AI-based traffic engineering, among others. © 2024 by the authors.},
document_type={Review},
source={Scopus},
}

Ref 10

@ARTICLE{Li2023,
author={Li, M. and Deng, S. and Zhou, H. and Qin, Y.},
title={A path selection scheme for detecting malicious behavior based on deep reinforcement learning in SDN/NFV-Enabled network},
journal={Computer Networks},
year={2023},
}
volume={236},
doi={10.1016/j.comnet.2023.110034},
art_number={110034},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173149348&doi=10.1016%2fj.comnet.2023.110034&partnerID=40&md5=36383e0940a3249bf22d68170beb5949},
abstract={The SDN/NFV network is prone to different types of attacks. The Distributed Denial of Service (DDoS) attack has the most severe impact as it can overwhelm the critical components of SDN/NFV to degrade its performance. We propose a closed-loop security architecture (SFCSA) and virtualize detection methods as network service functions in this article. Combining the detection methods forms detection paths, in which different detection paths affect security performance differently. Further, we model the path selection problem as a Markov Decision Process, where the reward balances the malicious traffic detection capability and end-to-end latency. Then, an integrated deep reinforcement learning and convolution neural network path selection algorithm (CNNQ) is proposed. Furthermore, we define a total path malicious traffic detection capability metric. The defined metrics and common metrics are applied to evaluate the building prototype, with the corresponding experimental results demonstrating that the detection performance when combining multiple detection modules outperforms a single detection-based module. Besides, we verify the effectiveness of the CNNQ method under various DDoS attacks scenarios and present the fine-grained classification results of the selected detection modules. © 2023 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

Ref 16

@ARTICLE{Phu2023,
author={Phu, A.T. and Li, B. and Ullah, F. and Ul Huque, T. and Naha, R. and Babar, M.A. and Nguyen, H.},
title={Defending SDN against packet injection attacks using deep learning},
journal={Computer Networks},
year={2023},
}
volume={234},
doi={10.1016/j.comnet.2023.109935},
art_number={109935},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166658807&doi=10.1016%2fj.comnet.2023.109935&partnerID=40&md5=9fb9a5b42f37248c99985510fecc90b8},
abstract={The (logically) centralized architecture of software-defined networks makes them an easy target for packet injection attacks. In these attacks, the attacker injects malicious packets into the SDN network to affect the services and performance of the SDN controller and overflows the capacity of the SDN switches. Such attacks have been shown to ultimately stop the network functioning in real-time, leading to network breakdowns. There have been significant works on detecting and defending against similar DoS attacks in non-SDN networks, but detection and protection techniques for SDN against packet injection attacks are still in their infancy. Furthermore, many of the proposed solutions have been shown to be easily bypassed by simple modifications to the attacking packets or by altering the attacking profile. In this paper, we develop novel Graph Convolutional Neural Network models and algorithms for grouping network nodes/users into security classes by learning from network data. We start with two simple classes — nodes that engage in suspicious packet injection attacks and nodes that are not. From these classes, we then partition the network into separate segments with different security policies using distributed Ryu controllers in an SDN network. We show in experiments on an emulated SDN that our detection solution outperforms alternative approaches with above 99% detection accuracy for various types (both old and new) of injection attacks. More importantly, our mitigation solution maintains continuous functions of non-compromised nodes while isolating compromised/suspicious nodes in real-time. All code and data are publicly available for the reproducibility of our results. © 2023 The Author(s)},
document_type={Article},
source={Scopus},
}

//Survey paper (ref 12 in citations)

@ARTICLE{Lin20231781,
author={Lin, H. and Liu, Y. and Li, S. and Qu, X.},
title={How Generative Adversarial Networks Promote the Development of Intelligent Transportation Systems: A Survey},
journal={IEEE/CAA Journal of Automatica Sinica},
year={2023},
}
volume={10},
number={9},
pages={1781-1796},
doi={10.1109/JAS.2023.123744},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166782868&doi=10.1109%2fJAS.2023.123744&partnerID=40&md5=bc21c5640ae1d418f30ed4a7077428da},
abstract={In current years, the improvement of deep learning has brought about tremendous changes: As a type of unsupervised deep learning algorithm, generative adversarial networks (GANs) have been widely employed in various fields including transportation. This paper reviews the development of GANs and their applications in the transportation domain. Specifically, many adopted GAN variants for autonomous driving are classified and demonstrated according to data generation, video trajectory prediction, and security of detection. To introduce GANs to traffic research, this review summarizes the related techniques for spatio-temporal, sparse data completion, and time-series data evaluation. GAN-based traffic anomaly inspections such as infrastructure detection and status monitoring are also assessed. Moreover, to promote further development of GANs in intelligent transportation systems (ITSs), challenges and noteworthy research directions on this topic are provided. In general, this survey summarizes 130 GAN-related references and provides comprehensive knowledge for scholars who desire to adopt GANs in their scientific works, especially transportation-related tasks. © 2014 Chinese Association of Automation.},
document_type={Article},
source={Scopus},
}

Ref 5

@CONFERENCE{Byakodi2023,
author={Byakodi, A.K. and Hungund, M.Z. and Athani, A.K.N. and Afghan, K.W.B. and Patil, S. and Narayan, D.G.},
title={Maximising Efficiency of Network Resources in SDN through Optimal Packet Routing using Reinforcement Learning},
journal={2023 International Conference on Computer Communication and Informatics, ICCCI 2023},
year={2023},
}
doi={10.1109/ICCCI56745.2023.10128241},
}
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163108881&doi=10.1109%2fICCCI56745.2023.10128241&partnerID=40&md5=43ae1c05f65d8646b8cbe08e2f723838},
abstract={Software-defined networking (SDN) has increased in popularity in recent years owing to its ability to centralize network device control. This is the cornerstone of data center networks, and as more IoT-enabled devices are added, it is expected to skyrocket. The employment of Machine Intelligence to handle and route the majority of traffic can enhance centralized SDN-based control, allowing for high and occasionally subpar network management. Owing to the development of Reinforcement Learning (RL) combined with Deep Learning, which allows autonomous flow management in SDN, intelligent routing has gained popularity. However, the existing SDN routing algorithm has poor link usage and is unable to update and change according to real-time network conditions, making it challenging to forecast and predict how communication networks will evolve in the future. Consequently, we present a routing optimization strategy based on Quality of Service (QoS) variables for SDN-based Data Center Networks using Deep Reinforcement Learning. We provide a reinforcement learning-based routing method for SDN that outperforms Dijkstra's shortest path in terms of the throughput and average latency. In the proposed method, we integrated SDN with RL, which takes input from the state in which the current network is and routes traffic to achieve the maximum QoS parameters. The parameters considered were the throughput and delay. The presented solution is a network-oriented, self-learning routing system named DeepQoSR, based on Advantage Actor-Critic Networks. We compared our proposed technique with traditional algorithms, such as the shortest path, and present our analysis. © 2023 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

base1 ( ref 6 in citations )

@article{devi2024robust,
  title={Robust AI Based Bio Inspired Protocol using GANs for Secure and Efficient Data Transmission in IoT to Minimize Data Loss},
  author={Devi, PA and Megala, D and Paviyasre, N and Nithyanandh, S},
  journal={Indian Journal of Science and Technology},
  volume={17},
  number={35},
  pages={3609--3622},
  year={2024}
}

base 2 ( ref 9 in citations )

@article{khan2024secure,
  title={Secure and Efficient AI-SDN-based Routing for Healthcare-Consumer Internet of Things},
  author={Khan, Nauman Ali and Din, Ikram Ud and Almogren, Ahmad and Altameem, Ayman and Guizani, Mohsen and others},
  journal={IEEE Transactions on Consumer Electronics},
  year={2024},
  publisher={IEEE}
}

base 3 (ref 24)

@article{song2025emergency,
  title={Emergency Routing Protocol for Intelligent Transportation Systems Using IoT and Generative Artificial Intelligence},
  author={Song, Shijun and Fan, Min},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2025},
  publisher={IEEE}
}

base 4 (ref 33)

@article{zhang2025adversarial,
  title={Adversarial generative flow network for solving vehicle routing problems},
  author={Zhang, Ni and Yang, Jingfeng and Cao, Zhiguang and Chi, Xu},
  journal={arXiv preprint arXiv:2503.01931},
  year={2025}
}

base 5 (ref 28)

@article{wang2024gtr,
  title={GTR: GAN-based trusted routing algorithm for underwater wireless sensor networks},
  author={Wang, Bin and Ben, Kerong},
  journal={Sensors},
  volume={24},
  number={15},
  pages={4879},
  year={2024},
  publisher={MDPI}
}